\section{Transformations}
\todo{introduce transformations}
\subsection{Affine}
One of the first transformations that was introduced was a simple affine transformation, 
componentwise. It was first introduced using an IAR flow-structure and later also with 
an AR flow-structure \autocite{iaf,maf}. One of the reasons they have been popular
with the aformentioned structures are partly due to the fact that the resulting flow 
can be inverted easily. However, the form of the function can easily be applied to many flow-structures. Which
is why we define it more generally here.
\begin{definition}
    Let \((\mathcal{A}, f)\) be a normalizing flow, with accompanied flow-structure \(\mathcal{S}\).
    An \emph{affine transformation} has the form 
    \begin{align*}
        z_{t,d} = f_{t,d}(z_{t-1,d}) = a_{t,d}\,z_{t-1,d} + b_{t,d},
    \end{align*}
    with \(a_{t,d}, b_{t,d} = \mathcal{H}(\mathcal{S}_{ext}(t,d))\).
    We refer to \((\mathcal{A},f)\) as an
    \emph{affine flow}, if \(f_{t,d}\) is an affine transformation for every \(t \in \mathcal{T}\) and
    \(d \in \mathcal{D}\). 
\end{definition}
Here \(\mathcal{H}\) can be any function with output \(a,b\) and input based off the exterior structure to 
the flow. We typically leverage the universality off neural networks and let \(\mathcal{H} = \mathcal{NN}\), for 
a certain number of hidden layers, activiation functions, and number of neurons. 
\todo{write more about affine and what properties of \(\mathcal{S}\) gives analytical inverse.}

\subsection{Neural Network Transformation}
Transforming the variables by using a neural network is not trivial, as one must be able to guarantee 
invertibility. One way to assure this was done by \cite{naf}, where they constrain the neural network that
transform \(z_{t,d}\) to a netowork with bijective activiation functions and nonnegative weights. We denote
these networks here by \(\mathcal{NN}^{+}\). 
\begin{definition}
    Let \((\mathcal{A}, f)\) be a normalizing flow, with accompanying structure \(\mathcal{S}\). A
    \emph{\(\mathcal{NN}^{+}\)-transformation} has the form
    \begin{align*}
        z_{t,d} = f_{t,d}(z_{t-1,d}) = \mathcal{NN}^{+}(z_{t-1,d}),
    \end{align*}
    with the weights of the network defined by \(W = \mathcal{H}(\mathcal{S}_{ext}(t,d))\). A normalizing flow
    is a \emph{\(\mathcal{NN}^{+}\)-flow}
    if for all \(t \in \mathcal{T}\) and \(d \in \mathcal{D}\), the transformation \(f_{t,d}\) is a 
    \(\mathcal{NN}^{+}\)-transformation.
\end{definition}

