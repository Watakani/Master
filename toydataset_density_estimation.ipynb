{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    " \n",
    "from functools import partial\n",
    "\n",
    "from NormalizingFlows.src.train import train_backward_with_tuning, train_backward\n",
    "from NormalizingFlows.src.scores import log_likelihood, difference_loglik\n",
    "from NormalizingFlows.src.utils import update_device, load_best_model, load_checkpoint_model\n",
    "\n",
    "from NormalizingFlows.src.flows import *\n",
    "\n",
    "from NormalizingFlows.src.data.density.toydata import ToyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device_cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_distr = torch.distributions.exponential.Exponential(torch.tensor([0.5]).to(device))\n",
    "#target_distr = torch.distributions.gamma.Gamma(torch.tensor([1.0]).to(device), torch.tensor([5.0]).to(device))\n",
    "#target_distr = torch.distributions.cauchy.Cauchy(torch.tensor([4.0]), torch.tensor([2.0]))\n",
    "#dataset = ToyDataset(data_distr=target_distr, dim_input=4, samples=1000)\n",
    "#target_distr = torch.distributions.studentT.StudentT(torch.tensor(5.0))\n",
    "\n",
    "#means = torch.tensor([[-20.0,0.0],\n",
    "#                      [0.0,0.0],\n",
    "#                      [30.0,-14.0]])\n",
    "#mix = torch.distributions.categorical.Categorical(torch.ones(3,))\n",
    "#comp = torch.distributions.independent.Independent(torch.distributions.normal.Normal(\n",
    "#             means, torch.rand(3,2)), 1)\n",
    "#target_distr = torch.distributions.mixture_same_family.MixtureSameFamily(mix, comp)\n",
    "\n",
    "\n",
    "dim_input = 50\n",
    "target_distr = torch.distributions.independent.Independent(\n",
    "            torch.distributions.exponential.Exponential((torch.FloatTensor(dim_input).uniform_(4, 10)).to(device)),1)\n",
    "\n",
    "#dataset = ToyDataset(dim_input=50, samples=10000)\n",
    "dataset = ToyDataset(dim_input=dim_input,data_distr=target_distr, samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = dataset.dim_input\n",
    "num_trans = 6 #Must be even\n",
    "perm_types = ['identity', 'alternate','random']\n",
    "dim_hidden = [80,80,50]\n",
    "flows, names = [], []\n",
    "flow_forward=False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Linear and mean field\n",
    "\n",
    "transformations = create_constant_trans(num_trans, dim_input, flow_forward)\n",
    "mean_field = create_flows_with_identity(dim_input, transformations, flow_forward) \n",
    "name = 'Mean field'\n",
    "flows.append(mean_field), names.append(name)\n",
    "\n",
    "transformations = create_linear_bias_trans(num_trans, dim_in, forward_flow)\n",
    "linear = create_flows_with_identity(dim_input, transformations, flow_forward)\n",
    "name = 'Linear'\n",
    "flows.append(linear), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affine flows with two block\n",
    "\n",
    "transformations = create_affine_trans(num_trans, dim_input, flow_forward)\n",
    "aff_coup_id = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'Affine coupling identity'\n",
    "flows.append(aff_coup_id), names.append(name)\n",
    "\n",
    "transformations = create_affine_trans(num_trans, dim_input, flow_forward)\n",
    "aff_coup_alt = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'Affine coupling alternating'\n",
    "flows.append(aff_coup_alt), names.append(name)\n",
    "\n",
    "transformations = create_affine_trans(num_trans, dim_input, flow_forward)\n",
    "aff_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'Affine coupling random'\n",
    "flows.append(aff_coup_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affine flows with AR\n",
    "\n",
    "transformations = create_affine_trans(num_trans, dim_input, flow_forward)\n",
    "aff_ar_id = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'Affine AR identity'\n",
    "flows.append(aff_ar_id), names.append(name)\n",
    "\n",
    "transformations = create_affine_trans(num_trans, dim_input, flow_forward)\n",
    "aff_ar_alt = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'Affine AR alternate'\n",
    "flows.append(aff_ar_alt), names.append(name)\n",
    "\n",
    "transformations = create_affine_trans(num_trans, dim_input, flow_forward)\n",
    "aff_ar_rand = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'Affine AR random'\n",
    "flows.append(aff_ar_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PiecewiseAffine flows with coupling\n",
    "\n",
    "transformations = create_piecewise_trans(num_trans, forward_flow)\n",
    "piec_coup_id = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'PiecewiseAffine coupling identity'\n",
    "flows.append(piec_coup_id), names.append(name)\n",
    "\n",
    "transformations = create_piecewise_trans(num_trans, forward_flow)\n",
    "piec_coup_alt = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'PiecewiseAffine coupling alternate'\n",
    "flows.append(piec_coup_alt), names.append(name)\n",
    "\n",
    "transformations = create_piecewise_trans(num_trans, forward_flow)\n",
    "piec_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'PiecewiseAffine coupling random'\n",
    "flows.append(piec_coup_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PiecewiseAffine flows with AR\n",
    "\n",
    "transformations = create_piecewise_trans(num_trans, forward_flow)\n",
    "piec_ar_id = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'PiecewiseAffine AR identity'\n",
    "flows.append(piec_ar_id), names.append(name)\n",
    "\n",
    "transformations = create_piecewise_trans(num_trans, forward_flow)\n",
    "piec_ar_alt = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'PiecewiseAffine AR alternate'\n",
    "flows.append(piec_ar_alt), names.append(name)\n",
    "\n",
    "transformations = create_piecewise_trans(num_trans, forward_flow)\n",
    "piec_ar_rand = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'PiecewiseAffine AR random'\n",
    "flows.append(piec_ar_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PiecewiseAffineAffine with twoblock\n",
    "\n",
    "transformations = create_affinepiecewise_trans(num_trans, forward_flow)\n",
    "piecaf_coup_id = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'PiecewiseAffineAffine coupling identity'\n",
    "flows.append(piecaf_coup_id), names.append(name)\n",
    "\n",
    "transformations = create_affinepiecewise_trans(num_trans, forward_flow)\n",
    "piecaf_coup_alt = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'PiecewiseAffineAffine coupling alternate'\n",
    "flows.append(piecaf_coup_alt), names.append(name)\n",
    "\n",
    "transformations = create_affinepiecewise_trans(num_trans, forward_flow)\n",
    "piecaf_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'PiecewiseAffineAffine coupling random'\n",
    "flows.append(piecaf_coup_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PiecewiseAffineAffine with AR\n",
    "\n",
    "transformations = create_affinepiecewise_trans(num_trans, forward_flow)\n",
    "piecaf_ar_id = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'PiecewiseAffineAffine AR identity'\n",
    "flows.append(piecaf_ar_id), names.append(name)\n",
    "\n",
    "transformations = create_affinepiecewise_trans(num_trans, forward_flow)\n",
    "piecaf_ar_alt = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'PiecewiseAffineAffine AR alternate'\n",
    "flows.append(piecaf_ar_alt), names.append(name)\n",
    "\n",
    "transformations = create_affinepiecewise_trans(num_trans, forward_flow)\n",
    "piecaf_ar_rand = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'PiecewiseAffineAffine AR random'\n",
    "flows.append(piecaf_ar_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ContinuousPiecewise with twoblock\n",
    "\n",
    "transformations = create_continuous_piecewise_trans(num_trans, forward_flow)\n",
    "conpiec_coup_iden = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffine coupling identity'\n",
    "flows.append(conpiec_coup_iden), names.append(name)\n",
    "\n",
    "transformations = create_continuous_piecewise_trans(num_trans, forward_flow)\n",
    "conpiec_coup_alt = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffine coupling alternate'\n",
    "flows.append(conpiec_coup_alt), names.append(name)\n",
    "\n",
    "transformations = create_continuous_piecewise_trans(num_trans, forward_flow)\n",
    "conpiec_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffine coupling random'\n",
    "flows.append(conpiec_coup_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ContinuousPiecewise with AR\n",
    "\n",
    "transformations = create_continuous_piecewise_trans(num_trans, forward_flow)\n",
    "conpiec_ar_iden = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffine AR identity'\n",
    "flows.append(conpiec_ar_iden), names.append(name)\n",
    "\n",
    "transformations = create_continuous_piecewise_trans(num_trans, forward_flow)\n",
    "conpiec_ar_alt = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffine AR alternate'\n",
    "flows.append(conpiec_ar_alt), names.append(name)\n",
    "\n",
    "transformations = create_continuous_piecewise_trans(num_trans, forward_flow)\n",
    "conpiec_ar_rand = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffine AR random'\n",
    "flows.append(conpiec_ar_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ContinuousPiecewiseAffine with twoblock\n",
    "\n",
    "transformations = create_affinecontinuous_trans(num_trans, forward_flow)\n",
    "affconpiec_coup_iden = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffineAffine coupling identity'\n",
    "flows.append(affconpiec_coup_iden), names.append(name)\n",
    "\n",
    "transformations = create_affinecontinuous_trans(num_trans, forward_flow)\n",
    "affconpiec_coup_alt = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffineAffine coupling alternate'\n",
    "flows.append(affconpiec_coup_alt), names.append(name)\n",
    "\n",
    "transformations = create_affinecontinuous_trans(num_trans, forward_flow)\n",
    "affconpiec_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffineAffine coupling random'\n",
    "flows.append(affconpiec_coup_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ContinuousPiecewiseAffine with AR\n",
    "\n",
    "transformations = create_affinecontinuous_trans(num_trans, forward_flow)\n",
    "affconpiec_ar_iden = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[0], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffineAffine AR identity'\n",
    "flows.append(affconpiec_ar_iden), names.append(name)\n",
    "\n",
    "transformations = create_affinecontinuous_trans(num_trans, forward_flow)\n",
    "affconpiec_ar_alt = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[1], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffineAffine AR alternate'\n",
    "flows.append(affconpiec_ar_alt), names.append(name)\n",
    "\n",
    "transformations = create_affinecontinuous_trans(num_trans, forward_flow)\n",
    "affconpiec_ar_rand = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'ContinuousPiecewiseAffineAffine AR random'\n",
    "flows.append(affconpiec_ar_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternating Piecewise Affine with twoblock\n",
    "\n",
    "transformations = create_alt_piecewise_affine_trans(num_trans, forward_flow)\n",
    "afpiec_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'Alternating Affin_PiecewiseAffine coupling random'\n",
    "flows.append(afpiec_coup_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternating Piecewise Affine with AR\n",
    "\n",
    "transformations = create_alt_piecewise_affine_trans(num_trans, forward_flow)\n",
    "afpiec_ar_rand = create_flows_with_AR(dim_input, dim_hidden, transformations, perm_types[2], flow_forward)\n",
    "name = 'Alternating Affin_PiecewiseAffine AR random'\n",
    "flows.append(afpiec_ar_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternating with Linear layer and Affine\n",
    "\n",
    "transformations = create_alt_linear_affine_trans(num_trans, dim_input, forward_flow)\n",
    "linaff_coup_iden = create_flows_with_twoblock(dim_input, dim_hidden, num_trans, perm_types[0], flow_forward)\n",
    "name = 'Alternating Linear_Affine coupling identity'\n",
    "flows.append(linaff_coup_iden), names.append(name)\n",
    "\n",
    "transformations = create_alt_linear_affine_trans(num_trans, dim_input, forward_flow)\n",
    "linaff_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, num_trans, perm_types[2], flow_forward)\n",
    "name = 'Alternating Linear_Affine coupling random'\n",
    "flows.append(linaff_coup_rand), names.append(name)\n",
    "\n",
    "transformations = create_alt_linear_affine_trans(num_trans, dim_input, forward_flow)\n",
    "linaff_ar_iden = create_flows_with_AR(dim_input, dim_hidden, num_trans, perm_types[0], flow_forward)\n",
    "name = 'Alternating Linear_Affine AR identity'\n",
    "flows.append(linaff_ar_iden), names.append(name)\n",
    "\n",
    "transformations = create_alt_linear_affine_trans(num_trans, dim_input, forward_flow)\n",
    "linaff_ar_rand = create_flows_with_AR(dim_input, dim_hidden, num_trans, perm_types[2], flow_forward)\n",
    "name = 'Alternating Linear_Affine AR random'\n",
    "flows.append(linaff_ar_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = create_alt_linear_piecewise_trans(num_trans, dim_input, forward_flow)\n",
    "linpiece_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, num_trans, perm_types[2], flow_forward)\n",
    "name = 'Alternating Linear_PiecewiseAffine coupling random'\n",
    "flows.append(linpiece_coup_rand), names.append(name)\n",
    "\n",
    "transformations = create_alt_linear_continuous_trans(num_trans, dim_input, forward_flow)\n",
    "lincont_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, num_trans, perm_types[2], flow_forward)\n",
    "name = 'Alternating Linear_ContinuousPiece coupling random'\n",
    "flows.append(lincont_coup_rand), names.append(name)\n",
    "\n",
    "transformations = create_alt_linear_affinepiecewise_trans(num_trans, dim_input, forward_flow)\n",
    "linaffpiec_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, num_trans, perm_types[2], flow_forward)\n",
    "name = 'Alternating Linear_AffinePiece coupling random'\n",
    "flows.append(linaffpiec_coup_rand), names.append(name)\n",
    "\n",
    "transformations = create_alt_linear_affinecontinuous_trans(num_trans, dim_input, forward_flow)\n",
    "linaffcont_coup_rand = create_flows_with_twoblock(dim_input, dim_hidden, num_trans, perm_types[2], flow_forward)\n",
    "name = 'Alternating Linear_AffineContinuous coupling random'\n",
    "flows.append(linaffcont_coup_rand), names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, flow in enumerate(flows):\n",
    "    flow.name = names[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning = False\n",
    "if tuning:\n",
    "    losses = []\n",
    "    optimizers = []\n",
    "\n",
    "    epochs = 200\n",
    "    batch_size = 16\n",
    "    num_hyperparam_samples = 4\n",
    "\n",
    "    config = {\n",
    "        'lr': tune.loguniform(1e-4, 1e-1),\n",
    "        'weight_decay': tune.loguniform(1e-5, 1e-1)\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        time_attr='training_iteration',\n",
    "        metric=\"loss\",\n",
    "        mode='min',\n",
    "        max_t=epochs,\n",
    "        grace_period=100,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    reporter=CLIReporter(\n",
    "        metric_columns=['loss', 'training_iteration']\n",
    "    )\n",
    "\n",
    "    for ind, flow in enumerate(flows):\n",
    "        update_device(device_cpu, flow, dataset)\n",
    "        result = tune.run(\n",
    "            partial(train_backward_with_tuning, model=flow, dataset=dataset, epochs=epochs, batch_size=batch_size, print_n=epochs+1, name=names[ind]),\n",
    "            config=config,\n",
    "            num_samples=num_hyperparam_samples,\n",
    "            scheduler=scheduler,\n",
    "            progress_reporter=reporter,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        update_device(device_cpu, flow, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True\n",
    "if training:\n",
    "    losses = []\n",
    "    optimizers = []\n",
    "\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "\n",
    "    for i in range(len(flows)):\n",
    "        flow = flows[i]\n",
    "        update_device(device, flow, dataset)\n",
    "\n",
    "        #optimizer = torch.optim.AdamW(flow.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        optimizer = torch.optim.SGD(flow.parameters(), lr=1e-4,  weight_decay=1e-3)\n",
    "        optimizers.append(optimizer)\n",
    "\n",
    "        losses.append(train_backward(flow, dataset.get_training_data(), optimizer, epochs, batch_size, print_n=200, save_checkpoint=True, burn_in=-1))\n",
    "\n",
    "        update_device(device_cpu, flow, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional training with same optimizer\n",
    "additional_training = True\n",
    "if additional_training:\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    add_flows, add_optimizers, add_losses = [], [], []\n",
    "    for i in range(len(flows)):\n",
    "        flow, optimizer, loss = load_checkpoint_model(flows[i], optimizers[i])\n",
    "        add_flows.append(flow)\n",
    "        add_optimizers.append(optimizer)\n",
    "        add_losses.append(loss)\n",
    "    \n",
    "    flows, optimizers, losses = add_flows, add_optimizers, add_losses\n",
    "    \n",
    "    for i in range(len(flows)):\n",
    "        flow = flows[i]\n",
    "        update_device(device, flow, dataset)\n",
    "\n",
    "        optimizer = optimizers[i]\n",
    "\n",
    "        losses[i] += (train_backward(flow, dataset.get_training_data(), optimizer, epochs, batch_size, print_n=100, save_checkpoint=True, burn_in=1))\n",
    "\n",
    "        update_device(device_cpu, flow, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_flows = []\n",
    "for flow in flows:\n",
    "    best_flows.append(load_best_model(flow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scale = False\n",
    "from_iter = 75\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "for i in range(len(losses)):\n",
    "    plt.plot(losses[i], label=names[i], alpha=0.8)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "for i in range(len(losses)):\n",
    "    plt.plot((losses[i])[from_iter:], label=names[i], alpha=0.8)\n",
    "plt.legend()\n",
    "\n",
    "if log_scale:\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results based on training data:' + '\\n')\n",
    "\n",
    "train_data = dataset.get_training_data()\n",
    "mean_target = torch.mean(dataset.evaluate(train_data)).detach().numpy()\n",
    "for flow in best_flows:\n",
    "    log_lik, mean = log_likelihood(train_data, flow)\n",
    "    print(\"Mean loglikelihood for {}: {}\".format(str(flow), mean))\n",
    "    print(\"Difference between target and {} mean loglikelihood: {}\".format(str(flow), abs(mean-mean_target)))\n",
    "    \n",
    "    #log_lik_diff, mean_diff, median_diff = difference_loglik(train_data, dataset, flow)\n",
    "    #print(\"Mean difference from target loglikelihood for {}: {}\".format(str(flow), mean_diff))\n",
    "    #print(\"Median difference from target loglikelihood for {}: {} \\n\".format(str(flow), median_diff))\n",
    "    \n",
    "\n",
    "print(\"Mean loglikelihood with actual distribution: {}\".format(mean_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.get_training_data()\n",
    "mean_target = torch.mean(dataset.evaluate(train_data)).detach().numpy()\n",
    "mean_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results based on test data' + '\\n')\n",
    "\n",
    "test_data = dataset.get_test_data()\n",
    "mean_target = torch.mean(dataset.evaluate(test_data)).detach().numpy()\n",
    "for flow in best_flows:\n",
    "    log_lik, mean = log_likelihood(test_data, flow)\n",
    "    print(\"Mean loglikelihood for {}: {}\".format(str(flow), mean))\n",
    "    print(\"Difference between target and {} mean loglikelihood: {}\".format(str(flow), abs(mean-mean_target)))\n",
    "    \n",
    "    #log_lik_diff, mean_diff, median_diff = difference_loglik(test_data, dataset, flow)\n",
    "    #print(\"Mean difference from target loglikelihood for {}: {}\".format(str(flow), mean_diff))\n",
    "    #print(\"Median difference from target loglikelihood for {}: {} \\n\".format(str(flow), median_diff))\n",
    "    \n",
    "\n",
    "print(\"Mean loglikelihood with actual distribution: {}\".format(mean_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results based on new sample from each flow:' + '\\n')\n",
    "\n",
    "#mean_target = torch.mean(dataset.evaluate(sample_last)).detach().numpy()\n",
    "for flow in best_flows[:2]:\n",
    "    with torch.no_grad():\n",
    "        sample, log_prob = flow.sample(800)\n",
    "        sample_last = sample[-1]\n",
    "\n",
    "    log_lik, mean = log_likelihood(sample_last, flow)\n",
    "    print(\"Mean loglikelihood for {}: {}\".format(str(flow), mean))\n",
    "    print(\"Difference between target and {} mean loglikelihood: {}\".format(str(flow), abs(mean-mean_target)))\n",
    "    \n",
    "    log_lik_diff, mean_diff, median_diff = difference_loglik(sample_last, dataset, flow)\n",
    "    print(\"Mean difference from target loglikelihood for {}: {}\".format(str(flow), mean_diff))\n",
    "    print(\"Median difference from target loglikelihood for {}: {} \\n\".format(str(flow), median_diff))\n",
    "    mean_target = torch.mean(dataset.evaluate(sample_last)).detach().numpy()\n",
    "\n",
    "print(\"Mean loglikelihood with actual distribution: {}\".format(mean_target))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[2]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
